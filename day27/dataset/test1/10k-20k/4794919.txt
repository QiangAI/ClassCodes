岗位职责：
1、负责设计、开发、维护、重构分布式的网络爬虫，包括调度、抓取、维护、验证等爬虫工作
2、负责抽取算法和数据库建模的调研和设计，保证抽取、去重、分类、解析、增量融合入库等流程之后的数据结果
3、对反爬机制有研究，有能力破解复杂图片验证码/账号限制/ip限制
 
 工作要求：
1、985/211本科以上学历，计算机相关专业；
2、精通Linux和C/C++、PHP/Python、Java等一种或几种编程语言； 
3、至少1年及以上Hadoop开发与应用经验，熟悉MapReduce、spark、Sqoop、hbase、hive等主流大数据技术；
4、熟悉Linux平台，可以编程使用Hadoop和基于Hadoop开发大数据处理系统；
5、具有良好的语言表达和文档撰写能力；良好的自学能力，可以快速学习掌握新的方法和技术。
