任职资格：
1、计算机相关专业本科及以上学历； 
2、熟悉Hadoop、HDFS，MapReduce，Hive等开源分布式系统； 
3、熟悉Spark、SparkSQL、SparkStreaming、Storm等框架；
4、熟悉python、shell、java等中的1种以上 ；
5、3年以上工作经验，至少有1年大数据开发或分析经验； 
6、有持续学习的能力；喜欢开源软件，乐于知识分享；对工作认真负责；可以独立承担较大工作压力；
7、有物联网经验优先。 

岗位职责：
1、使用大数据相关的技术(Hive、hadoop、hdfs）解决业务相关问题； 
2、理解 HDFS 体系架构，并能给予Hive、HDFS、python、R、Spark、Zeus等工具构建离线系统； 
3、利用大数据平台实现对数据的分析和处理； 
4、负责各类离线系统的业务调研，并与公司其他部门负责沟通协调；
5、负责离线系统中数据处理工作（数据采集、清洗、汇总、集成等）；
6、负责协助完成离线系统中数据上下层衔接处理工作； 
7、负责各类离线系统的开发、部署等工作； 
8、负责各种高并发场景解决方案；
8、具有良好的逻辑思维能力，可以独立承担工作压力，善于学习，与团队沟通无障碍 。
