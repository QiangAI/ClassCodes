任职 资格 ： 
 1 、 计算机相关 专业本科 及 以上学历 ；   
 2 、 熟悉 Hadoop 、 HDFS ， MapReduce ， Hive 等 开源 分布式系统 ；   
 3 、 熟悉 Spark 、 SparkSQL 、 SparkStreaming 、 Storm 等 框架 ； 
 4 、 熟悉 python 、 shell 、 java 等 中 的 1 种 以上   ； 
 5 、 3 年 以上 工作 经验 ， 至少 有 1 年 大 数据 开发 或 分析 经验 ；   
 6 、 有 持续 学习 的 能力 ； 喜欢 开源 软件 ， 乐于 知识 分享 ； 对 工作 认真负责 ； 可以 独立 承担 较大 工作 压力 ； 
 7 、 有物 联网 经验 优先 。   
 
 岗位职责 ： 
 1 、 使用 大 数据 相关 的 技术 ( Hive 、 hadoop 、 hdfs ） 解决 业务 相关 问题 ；   
 2 、 理解   HDFS   体系 架构 ， 并 能 给予 Hive 、 HDFS 、 python 、 R 、 Spark 、 Zeus 等 工具 构建 离线 系统 ；   
 3 、 利用 大 数据 平台 实现 对 数据 的 分析 和 处理 ；   
 4 、 负责 各类 离线 系统 的 业务 调研 ， 并 与 公司 其他 部门 负责 沟通 协调 ； 
 5 、 负责 离线 系统 中 数据处理 工作 （ 数据 采集 、 清洗 、 汇总 、 集成 等 ） ； 
 6 、 负责 协助 完成 离线 系统 中 数据 上 下层 衔接 处理 工作 ；   
 7 、 负责 各类 离线 系统 的 开发 、 部署 等 工作 ；   
 8 、 负责 各种 高 并发 场景 解决方案 ； 
 8 、 具有 良好 的 逻辑思维 能力 ， 可以 独立 承担 工作 压力 ， 善于 学习 ， 与 团队 沟通 无障碍   。