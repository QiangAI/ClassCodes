岗位职责 ： 
 1 .         对 指定 的 多个 网站 进行 网页 抓取 、 数据 提取 ； 破解 反爬 策略 , 例如 ： 淘宝 , 京东 , 运营商 等 
 2 .       负责 网页 信息 抽取 、 数据 清洗 、 入库 、 服务化 等 研发 和 优化 工作 
 3 .       负责 设计 和 开发 分布式 网络 爬虫 系统 ， 进行 多 平台 信息 的 抓取 和 分析 工作 
 4 .         改进 优化 现有 系统 架构 
 5 .       负责 线上 问题 debug 及 性能 调优 
 6 .       完成 各类 产品 数据 需求 和 接口 
 
 任职 要求 ： 
 1 .       有 扎实 的 java / Python 开发 基础 ， 或者 实践经验 ， 对 熟悉 爬虫 工具 
 2 .       熟悉 SSH 等 主流 开源 框架 
 3 .       熟悉 MySQL 或 同类 关系 型 数据库 
 4 .       熟悉 httpclient 、 jsoup 、 webdriver 、 htmlunit 、 Nutch 、 selenium 等 技术 
 5 .       了解 相关 反爬 规则 及 策略 ， 并 有 相关 攻破 理论 及 经验 
 6 .       负责 爬虫 系统优化 ， 并 能 监控 爬虫 进度 和 报警 反馈 
 7 .       熟练 使用 redis 、 MongoDB 等 缓存 技术 
 8 .       有 分布式 项目 开发 经验 优先 
 9 .       有 Solr 或 其他 Lucence 相关 经验 的 优先 考虑