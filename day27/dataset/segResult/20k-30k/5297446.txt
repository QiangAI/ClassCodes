岗位职责 ： 
 1 、 负责 大 数据 集群 的 日常 维护 、 监控 、 异常 处理 等 工作 ， 保障 集群 稳定 运行 ； 2 、 负责 大 数据 自动化 运维 以及 数据 化 运营 平台 开发 工作 ； 3 、 负责 大 数据 集群 的 用户 管理 、 权限 管理 、 资源管理 、 性能 优化 等 ； 4 、 深入 理解 数据 平台 架构 ， 发现 并 解决 重大 故障 及 性能 瓶颈 ， 打造 一流 的 数据 平台 ； 5 、 跟进 大 数据 前沿技术 ， 不断 优化 数据 集群 ； 
 
 任职 要求 ： 
 1 、 2   年 以上 大 数据 运维 经验 ； 2 、 有 良好 的 计算机 和 网络 基础 ， 熟悉 linux 文件系统 、 内核 、 性能 调优 ， TCP / IP 、 HTTP 等 协议 ； 3 、 熟悉 大 数据 生态 ， 有 相关 （ HDFS 、 Hive 、 Hbase 、 Sqoop 、 Spark 、 Flume 、 Zookeeper 、 ES 、 Kafka ） 的 运维及 开发 经验 ； 4 、 熟练 使用 shell 、 python 等 脚本语言 开发 相关 运维 管理工具 ； 5 、 研究 过 Hadoop 源码 或者 提交 过 patch 源代码 、 性能 调优 着 优先 考虑