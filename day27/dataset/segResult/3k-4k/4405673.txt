工作 职责 ： 1 、 根据 业务 需求 ， 参与 数据模型 的 ETL 开发 ， ETL 流程 优化 以及 相关 技术 问题 的 解决 2 、 用 PySpark 开发 一些 spark 程序 
 岗位 要求 ： 1 、 本科 及 以上学历 ， 计算机 或 相关 专业 。 985 、 211 院校 优先 2 、 每周 至少 保证 4 天 工作 时间 ， 能够 连续 工作 至少 3 个 月 3 、 熟练掌握 python 语言 ， 熟悉 linux 操作 4 、 具备 良好 的 数据库 理论 基础知识 ， 较强 的 sql 书写能力 ， 熟练 使 MySQL 、 ES 、 MongoDB 等 一种 或 多种 数据库 5 、 扎实 的 计算机 基本功 ， 具备 良好 的 编程 习惯 ， 熟悉 常用 的 数据结构 和 算法 6 、 良好 的 逻辑思维 能力 和 沟通 能力 ， 具有 较强 的 数据 敏感性 
 有 转正 机会