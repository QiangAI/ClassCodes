岗位职责 ： 
 1 、 负责 设计 、 开发 、 维护 、 重构 分布式 的 网络 爬虫 ， 包括 调度 、 抓取 、 维护 、 验证 等 爬虫 工作 
 2 、 负责 抽取 算法 和 数据库 建模 的 调研 和 设计 ， 保证 抽取 、 去 重 、 分类 、 解析 、 增量 融合 入库 等 流程 之后 的 数据 结果 
 3 、 对 反 爬 机制 有 研究 ， 有 能力 破解 复杂 图片 验证码 / 账号 限制 / ip 限制 
   
   工作 要求 ： 
 1 、 985 / 211 本科 以上学历 ， 计算机相关 专业 ； 
 2 、 精通 Linux 和 C / C++ 、 PHP / Python 、 Java 等 一种 或 几种 编程语言 ；   
 3 、 至少 1 年 及 以上 Hadoop 开发 与 应用 经验 ， 熟悉 MapReduce 、 spark 、 Sqoop 、 hbase 、 hive 等 主流 大 数据 技术 ； 
 4 、 熟悉 Linux 平台 ， 可以 编程 使用 Hadoop 和 基于 Hadoop 开发 大 数据处理系统 ； 
 5 、 具有 良好 的 语言表达 和 文档 撰写 能力 ； 良好 的 自学能力 ， 可以 快速 学习 掌握 新 的 方法 和 技术 。