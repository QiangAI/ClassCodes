职位 描述 
 1 、 负责 基于 Hadoop / Spark / Hive / Storm / kafka 等 分布式计算 平台 实现 离线 分析 、 实时 分析 的 计算 框架 ；   2 、 负责 平台 数据仓库 的 选型 、 设计 、 开发 、 维护 工作 ；   3 、 负责 上述 计算 平台 系统 的 可用性 、 容量 、 性能 、 监控 、 发布 、 安全 等 运维 管理工作 ， 确保 系统 持续 稳定 、 高效 运行 ；   4 、 协调 大 数据 团队 高效 的 进行 数据处理 、 分析 、 统计 、 挖掘 工作 ； 
 
 岗位 要求 ： 
 1 、 熟悉 服务器 / 存储 / 网络 / OS 等 基础架构 基本 元素 ， 熟悉 linux 操作系统 ， 具备 较强 的 调优 排障 能力 ；   2 、 熟悉 Hadoop 、 Spark 等 大 数据 框架 ， 有 大型 分布式计算 开发 、 部署 等 相关 经验 ；   3 、 熟悉 shell / python 或 其他 脚本语言 中 的 任意 一门 ， 有 扎实 的 Java 开发 基础 ， 了解 jvm 的 运行机制 以及 相应 调优 ；   4 、 能够 独立 完成 项目 的 系统分析 、 设计 ， 并 主导 完成 详细 设计 和 编码 的 任务 。   5 、 注重 性能 ， 良好 的 代码 管理 及 重构 意识 。 具备 独立 沟通 需求 ， 设计 ， 架构 ， 开发 的 能力 ；   6 、 熟悉 主流 的 数据 存储 产品 ， 有 开发 经验 者 优先 。 如 ： HBase ， Hive ， Redis ， MongoDB ， MySQL 等 ；   7 、 有 团队 管理 经验 者 优先 。