工作 职责 : 1 . 负责 大 数据 平台 （ CDH ） 优化 和 维护 ； 2 . 负责 数据 的 ETL ； 3 . 负责 算法 模型 上线 。 任职 资格 : 1 .   本科 及 以上学历 ， 3 年 以上 大 数据 相关 工作 经验 ； 2 .   熟悉 hadoop 生态 （ yarn   hdfs   spark   kafka 等 ） ， 熟练 使用 sqoop 同步 数据 ； 3 .   熟练掌握 PYTHON 、 JAVA ； 4 .   具有 团队 合作 、 良好 的 沟通 技巧 和 主动 挑战 困难 能力 。