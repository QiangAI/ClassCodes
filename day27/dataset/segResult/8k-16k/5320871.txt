岗位职责 ：   1 .   参与 分布式 爬虫 和 数据 采集 系统 的 架构设计 和 开发 ；   2 .   负责 网络 数据 抓取 规划 、 清洗 以及 汇总 的 开发 工作 ；   3 .   定期 爬取 指定 网站 的 数据 ， 为 业务部门 提供数据 支持 ；   任职 要求 ：   1 .   全日制 大学本科 及 以上学历 ， 计算机 、 软件工程 相关 专业 ,   两年 以上 python 开发 经验 ， 精通 python 网络 编程 ， 熟悉 HTTP 传输 协议 ；   2 .   了解 搜索 和 爬虫 开源 软件 ( lucene ， solr ， mathout ， firtex ， lemur ， indri ， nutch ， haddopmlarbin ， QT   webkit ) 的 一种 或 多种 ， 以及 相关 原理 ；   3 .   精通 网页 抓取 原理 及 技术 ， 精通 正则表达式 ， 从 结构化 的 和 非 结构化 的 数据 中 获取信息 ；   4 .   负责 设计 开发 数据 采集 策略 和 防 屏蔽 （ 反爬 ） 规则 ， 提升 数据 采集 的 效率 和 质量 ， 完成 定向 网站 数据 采集 的 相关 任务 5 .   具备 信息检索 、 web 挖掘 等 搜索引擎 相关 知识 ， 有 从事 网络 爬虫 、 网页 去 重 、 网页 信息 抓取 、 网页 分类 中任 一种 程序开发 经验 ；   6 .   熟悉 HTMLJavaScriptCSSxpathurlAjaxxml 等 Web 技术 熟悉 HttpClient 、 jsoup 、 WebDriver 、 phantomjs 等 工具 ; 7 .   熟悉 NoSql （ MongoDB ， Redis ， Hbase 等 ） ， 了解 大 数据 ， 有 一定 的 Hadoop 使用 经验 。 8 .   做事 有 责任心 、 有 想法 ， 热爱 技术 ， 喜欢 钻研 9 .   具备 极强 的 团队精神 和 合作 精神 ， 富有 工作 热情 及 责任感