工作 职责 : 1 、 根据 需求 完成 海量 数据 的 处理 任务 2 、 能够 对 关联 数据 进行 并行 图 挖掘 3 、 开发 高 并发 、 实时 的 流 处理 作业 4 、 对 Hadoop 、 Spark 进行 深度 定制 二次开发 5 、 对 数据 应用 进行 架构设计 6 、 运用 开源 大 数据 软件 解决问题 任职 资格 : 1 、 至少 熟练掌握 Java 、 Python 、 Scala 中 的 两种 语言 2 、 掌握 Spark 、 MapReduce 开发 ， 掌握 作业 调优 方式 ， 有 海量 数据处理 经验 。 3 、 掌握 流 处理 框架 开发 ， Spark   Streaming 、 Flink 、 Storm 。 4 、 精通 Hive 、 Spark   SQL 开发 5 、 熟悉 主流 NoSQL 数据库 和 图 数据库 应用 开发 ， 如 HBase 、 MongoDB 、 Rediis 、 Neo4j 等 ， 有过 高 并发 读写 调优 经验 6 、 熟悉 主流 全文 搜索 框架 开发 ， 如 Solr 、 ES7 、 有大 数据 架构 经验 ， 能够 根据 需求 完成 大 数据 架构设计 8 、 熟悉 Hadoop 、 Spark 生态圈 ， 能 运用 其 解决问题 9 、 良好 的 沟通 ， 团队 合作 意识 ， 非常 强 的 学习 能力