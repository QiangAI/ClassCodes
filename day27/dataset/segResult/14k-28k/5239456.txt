工作 职责 ： 
 1 ， 负责 基于 spark , hadoop , hbase 等 组件 的 大 数据 计算 优化 
 2 ， 负责 设计 ， 开发 和 优化 数据 接入 ， 存储 ， 调度 等 大 数据 基础 平台 
 3 ， 负责 高性能 服务 接口 设计 实现 
 4 ， 能 积极主动 研究 大 数据 各种 前沿技术 ， 在 产品 中 考虑 应用 
   任职 要求 ： 
 1 ,     3 年 以上 大 数据 开发 经验 ， 本科 以上学历 
 2 ， 具备 扎实 的 java 语言 基础 ， 掌握 shell / python / scala 语言 的 基本 使用 
 3 ， 熟悉 并行计算 或者 分布式计算 原理 ， 有 丰富 的 基于 hadoop , spark , hbase 等 组件 开发 的 经验 
 4 ， 对 高 并发 ， 高性能 服务 接口 有 一定 开发 经验 
 5 ， 熟悉 zookeeper / kafka / flume / flink 等 平台 和 aws 使用 经验 者 优先 
 6 ， 有 DMP 系统 或者 互联网 广告行业 经验 者 优先 。 
 7 ， 良好 的 自我 学习 和 自我 驱动 能力