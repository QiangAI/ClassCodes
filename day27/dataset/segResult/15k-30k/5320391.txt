岗位职责 :     1 、 负责 公司 Hadoop / HBase / Storm / Spark 等 大 数据 基础设施 的 研发 与 运维 ， 提升 运行 效率 、 稳定性 和 可用性 ；     2 、 负责 实时 数据分析 和 数据挖掘     3 、 完善 大 数据 平台 相关 制度 及 应用 规范 ， 指导 开发人员 和 运维 人员 ；     4 、 配合 技术 经理 规划设计 与 实施 大 数据 应用 。         要求 ：     1 、 本科 及 以上学历     2 、 精通 Java 语言 开发 ， 熟悉 Python 、 Scala 或者 Go 语言 之一 ,     熟练掌握 Linux 操作系统 。     3 、 熟悉 Hadoop 生态圈 的 相关 组件 ， 如 HDFS 、 HBase 、 Hive 、 Spark 、 YARN 、 MR 等 ， 具备 2 年 以上 Hadoop / Spark 开发 及 调优 经验 。     3 、 熟悉 主流 数据库 （ 如 Oracle 、 MySQL ）     5 .   熟悉 实时 流 计算 框架 Storm 、 Flink 和 Spark   streaming 其中 一种 。     5 、 熟悉 ETL 、 BI 、 数据分析 方法 、 机器 学习 、 数据挖掘 经验 者 优先 。     6 、 具备 较强 的 学习 能力 和 自我管理 能力 ， 性格 积极 乐观 ， 能够 在 压力 环境 下 工作 。