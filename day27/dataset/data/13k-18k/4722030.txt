【岗位职责】
1、负责基于hadoop/spark生态系统、搜索引擎的产品研发；
2、基于海量用户行为数据和其他数据，分析和研究数据与实际业务的关联关系，并与实际业务应用相结合开发；
3、负责大数据分析需求设计和开发，承担数据抽取、清洗、转化等数据处理程序开发。

【任职要求】
1、熟悉spark/Hadoop全栈优先；
2、熟练使用hadoop及hadoop生态圈中的常用组件
3、统招本科以上学历，计算机、软件工程、应用数字等理工科相关专业，2年以上的大数据平台架构经验；
4、理解云计算、大数据产品和数据分析相关技术和实现方法，并有相关项目经验；
5、至少熟悉java、python等一种语言，熟悉掌握MYSQL；
