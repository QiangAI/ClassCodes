职位描述：
负责建立一个复杂的大数据分析平台，用于改变大型工业管理其资产的方式
建立高度可扩展的框架，用于获取、转化、增强 IoT规模的数据
建立分布式存储和计算系统，
使用Hadoop生态系统组件开发数据结构和流程
负责ETL，Data Pipeline
实施机器学习算法于软件上
了解世界前沿的工具和框架，并能够针对具体任务选择最佳工具

任职要求：
计算机、软件工程等相关专业本科，研究生学位优先
3年以上系统开发经验
优秀的编程能力，熟悉掌握Python、Java
熟悉各种数据处理技术（Hadoop，Spark，Kafka等）
1年以上NoSQL数据库经验
具有REST API的经验或知识，并通过微服务提供数据。
使用版本控制（Git等）进行协作代码开发的经验。

加分项：
作为开源贡献者的经验
有数据建模（机器学习）经验
在Github上有上传代码或demo
