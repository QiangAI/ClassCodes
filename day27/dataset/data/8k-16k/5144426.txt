工作职责:1、根据需求完成海量数据的处理任务2、能够对关联数据进行并行图挖掘3、开发高并发、实时的流处理作业4、对Hadoop、Spark进行深度定制二次开发5、对数据应用进行架构设计6、运用开源大数据软件解决问题任职资格:1、至少熟练掌握Java、Python、Scala中的两种语言2、掌握Spark、MapReduce开发，掌握作业调优方式，有海量数据处理经验。3、掌握流处理框架开发，Spark Streaming、Flink、Storm。4、精通Hive、Spark SQL开发5、熟悉主流NoSQL数据库和图数据库应用开发，如HBase、MongoDB、Rediis、Neo4j等，有过高并发读写调优经验6、熟悉主流全文搜索框架开发，如Solr、ES7、有大数据架构经验，能够根据需求完成大数据架构设计8、熟悉Hadoop、Spark生态圈，能运用其解决问题9、良好的沟通，团队合作意识，非常强的学习能力
