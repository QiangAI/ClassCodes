岗位职责
 1、基于HADOOP数据平台，参与数据开发及各类数据模型建设工作；
 2、基于HADOOP数据平台的规划升级，参与生态圈内工具创新及研发工作；
 3、参与公司大数据类研发项目，结合大数据平台探索应用场景并参与实施；
 
任职条件
 1、本科以上学历，计算机相关专业，4年以上IT开发工作经验；
 2、熟练使用Hadoop/Spark生态圈技术，如：Hive、Hbase、MapReduce、Spark、Oozie、Kafka、Flume等；
 3、熟悉Sql编程及性能调优；
 4、熟悉LINUX常用命令，熟悉python,shell等脚本语言;
 5、了解开源各种数据仓库工具，如数据同步工具，调度工具，报表展示工具；
 6、具备较高的程序开发及调试能力；具备一定的系统设计能力；
 7、良好的沟通技巧和团队合作意识。
