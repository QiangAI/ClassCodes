职位描述
1、负责基于Hadoop/Spark/Hive/Storm/kafka等分布式计算平台实现离线分析、实时分析的计算框架； 2、负责平台数据仓库的选型、设计、开发、维护工作； 3、负责上述计算平台系统的可用性、容量、性能、监控、发布、安全等运维管理工作，确保系统持续稳定、高效运行； 4、协调大数据团队高效的进行数据处理、分析、统计、挖掘工作；

岗位要求：
1、熟悉服务器/存储/网络/OS等基础架构基本元素，熟悉linux操作系统，具备较强的调优排障能力； 2、熟悉Hadoop、Spark等大数据框架，有大型分布式计算开发、部署等相关经验； 3、熟悉shell/python或其他脚本语言中的任意一门，有扎实的Java开发基础，了解jvm的运行机制以及相应调优； 4、能够独立完成项目的系统分析、设计，并主导完成详细设计和编码的任务。 5、注重性能，良好的代码管理及重构意识。具备独立沟通需求，设计，架构，开发的能力； 6、熟悉主流的数据存储产品，有开发经验者优先。如：HBase，Hive，Redis，MongoDB，MySQL等； 7、有团队管理经验者优先。

 

