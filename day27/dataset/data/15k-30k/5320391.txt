岗位职责:  1、负责公司Hadoop/HBase/Storm/Spark等大数据基础设施的研发与运维，提升运行效率、稳定性和可用性；  2、负责实时数据分析和数据挖掘  3、完善大数据平台相关制度及应用规范，指导开发人员和运维人员；  4、配合技术经理规划设计与实施大数据应用。    要求：  1、本科及以上学历  2、精通Java语言开发，熟悉Python、Scala或者Go语言之一,  熟练掌握Linux操作系统。  3、熟悉Hadoop生态圈的相关组件，如HDFS、HBase、Hive、Spark、YARN、MR等，具备2年以上Hadoop/Spark开发及调优经验。  3、熟悉主流数据库（如Oracle、MySQL）  5. 熟悉实时流计算框架Storm、Flink和Spark streaming其中一种。  5、熟悉ETL、BI、数据分析方法、机器学习、数据挖掘经验者优先。  6、具备较强的学习能力和自我管理能力，性格积极乐观，能够在压力环境下工作。
