{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习算法分类\n",
    "\n",
    "1. 监督学习\n",
    "    - 训练样本：带标签或者期望值；\n",
    "        - 线性回归\n",
    "            - 局部加权\n",
    "            - Ridge回归\n",
    "            - LASSO回归\n",
    "        - Logistic回归\n",
    "            - 正则化（L1，L2惩罚项）\n",
    "        - SVM\n",
    "            - SVC【lassfier】\n",
    "            - SVR【egression】\n",
    "        - 决策树\n",
    "            - 随机森林\n",
    "            - XGBoost\n",
    "        - **Naive Bayes分类朴素贝叶斯分类**\n",
    "        \n",
    "        - KNN算法\n",
    "            \n",
    "        - **集成学习**\n",
    "            - ....\n",
    "            \n",
    "        - 神经网络\n",
    "            - .....（深度学习）\n",
    "\n",
    "2. 无监督学习\n",
    "    - 训练样本不带标签与期望值；\n",
    "        - 降维算法\n",
    "            - PCA\n",
    "            - FA\n",
    "            - ICA\n",
    "            - 核PCA\n",
    "        - 聚类算法\n",
    "            - K均值\n",
    "        - 规则关联\n",
    "            - **Apriori**    \n",
    "            \n",
    "3. 半监督学习\n",
    "    - 少量样本带标签\n",
    "    - 部分样本不带标签\n",
    "    \n",
    "\n",
    "4. 强化学习\n",
    "    - 惩罚或者奖励学习\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K均值算法\n",
    "\n",
    "- 聚类\n",
    "    - 基于人类的直觉形成的一个算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 算法过程：\n",
    "    - 假设样本集$X=[x_1,x_2,\\dots,x_n]$, 准备分成K类\n",
    "    \n",
    "    - 1. 在样本集中，随机选择K个质心点。\n",
    "    - 2. 循环计算训练样本到K个质心点的距离（欧氏距离，马氏距离，.....）\n",
    "    - 3. 每个样本点，具有K个距离，把样本点划分为吉距离最小的质心类别。\n",
    "    - 4. 每个一样本可以划分到k个质心所在类别。\n",
    "    \n",
    "    \n",
    "    - 5. 重新对新的类别，计算均值，得到K个质心点。然后重复上面的步骤。\n",
    "    \n",
    "    - 6. 算法结束：\n",
    "        - 质心点比较稳定：\n",
    "            - 下一次与上一次质心完全相等（在某个误差范围内，我们认为完全相等）。\n",
    "            - 指定迭代次数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn算法的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:896: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "  return_n_iter=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 2 1 2 2 2 2 1 2 2 2 2\n",
      " 2 2 1 1 2 2 2 2 1 2 1 2 1 2 2 1 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 1 2\n",
      " 2 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlp\n",
    "import sklearn.datasets as ds\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 数据集：鸢尾花\n",
    "data, target = ds.load_iris(return_X_y=True)\n",
    "\n",
    "data = data[:, [0, 2]]\n",
    "\n",
    "init = np.zeros(shape=(3, data.shape[1]), dtype=np.float32)\n",
    "\n",
    "init[0] = data[1]\n",
    "init[1] = data[51]\n",
    "init[2] =data[120]\n",
    "\n",
    "# 聚类\n",
    "cluster = KMeans(n_clusters=3, init= init)   # 选择初始质心点在不同的对应类别，计算结果的类别标号基本上就不会变。\n",
    "cluster.fit(data)    # 聚类过程：均值点（质心点），分类后的数据集\n",
    "\n",
    "# 使用样本测试分类效果\n",
    "labels = cluster.predict(data)\n",
    "print(labels)\n",
    "# 可视化\n",
    "figure = plt.figure('K均值', figsize=[8, 6])\n",
    "ax =figure.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "# 样本点\n",
    "colors = mlp.colors.ListedColormap([(1,0,0),(0,1,0),(0,0,1)])\n",
    "\n",
    "ax.scatter(data[:50, 0], data[:50, 1], c=labels[0:50],   cmap=colors, marker='v')\n",
    "ax.scatter(data[50:100, 0], data[50:100, 1], c=labels[50:100],   cmap=colors, marker='>')\n",
    "ax.scatter(data[100:150, 0], data[100:150, 1], c=labels[100:150],   cmap=colors, marker='^')\n",
    "# 质心点\n",
    "ax.scatter(cluster.cluster_centers_[:,0], cluster.cluster_centers_[:,1], color=(0,1,1))\n",
    "\n",
    "plt.show()\n",
    "print(((labels- target)==0).sum())   # \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法实现\n",
    "\n",
    "- 数值计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "data, _ = ds.load_iris(return_X_y=True)\n",
    "# 1.随机选择初始质心点\n",
    "tol = 0.0001   # 质心点稳定的误差\n",
    "cluster_num = 3  # 聚类的类别（经验 + 人的分析）、\n",
    "\n",
    "# 输出与中间数据缓冲\n",
    "# 质心点\n",
    "clusters = []   # 存放的是均值中心shape= (3, 4)\n",
    "\n",
    "#  聚类的样本集\n",
    "cls_clusters = {}   # 字典格式：{类别下标(0,1,2): [存放样本的下标] }     # 类别下标对应质心的下标\n",
    "\n",
    "# 质心初始化（在data中随机选择三个点）\n",
    "idx = np.random.choice( range(0, len(data)), cluster_num)\n",
    "for i in idx:\n",
    "    clusters.append(data[i])   # 取三个样本点作为随机质心点\n",
    "    # 聚类样本集的初始化\n",
    "\n",
    "for i in range(cluster_num): \n",
    "    cls_clusters[i] = []   # 初始化空的list\n",
    "\n",
    "is_cluster = True\n",
    "\n",
    "while is_cluster:\n",
    "    # 重新初始化聚类的样本集\n",
    "    cls_clusters = {}\n",
    "    for i in range(cluster_num): \n",
    "        cls_clusters[i] = []   # 初始化空的list\n",
    "        \n",
    "    # 2. 对样本点循环，计算到质心点的距离\n",
    "    for sample_idx in  range(len(data)):\n",
    "        # 计算到所有质心点的距离\n",
    "        # 保存到质心点的距离\n",
    "        distances = []\n",
    "        for cluster in clusters:\n",
    "            # 计算距离\n",
    "            # distance =  np.sqrt(np.dot(data[sample_idx] - cluster, data[sample_idx] - cluster))    # 计算两个样本的差\n",
    "            diff = (data[sample_idx] - cluster) **2\n",
    "            diff =diff.sum()\n",
    "            distance = np.sqrt(diff)\n",
    "            distances.append(distance)\n",
    "        # 3. 根据最小原则，对样本点进行聚类\n",
    "        # 找出最小值的下标(聚类的类别下标)\n",
    "        min_idx = np.argmin(distances)\n",
    "        cls_clusters[min_idx].append( sample_idx )\n",
    "    # print(cls_clusters)    \n",
    "    # 4. 重新计算质心点，从第2步开始重复（误差值，固定的循环步骤）\n",
    "    new_clusters = []     # 存放新的质心点\n",
    "\n",
    "    # 循环字典，计算新的聚类的质心点\n",
    "    for cls in cls_clusters:   # cls是字典的key，就是类别\n",
    "        # 取出对应类别的样本集的下标\n",
    "        data_cls_idx =  cls_clusters[cls]\n",
    "        # print(data_cls_idx)\n",
    "        # 根据聚类的下标计算均值\n",
    "        # 根据下标取样本\n",
    "        data_cls = data.take(data_cls_idx, axis=0)\n",
    "        cls_mean = data_cls.mean(axis=0)\n",
    "        # 产生新的质心点\n",
    "        new_clusters.append(cls_mean)\n",
    "\n",
    "    # 是否质心点稳定\n",
    "    # 计算新旧质心点的距离（误差）是否小于tol\n",
    "    is_cluster=False\n",
    "    for i in range(len(new_clusters)):\n",
    "        # 计算质心点的距离\n",
    "        delta = np.sqrt(((clusters[i] - new_clusters[i])**2).sum())\n",
    "        if delta > tol:\n",
    "            is_cluster = True\n",
    "            break\n",
    "    # 跟新新的质心点\n",
    "    clusters = new_clusters\n",
    "\n",
    "    \n",
    "# print(delta)\n",
    "# print('聚类结束')\n",
    "# print(cls_clusters[0])\n",
    "# print(cls_clusters[1])\n",
    "# print(cls_clusters[2])\n",
    "# 分类\n",
    "categories = []\n",
    "for i in range(len(data)):\n",
    "    # 判定样本点，在哪个类别\n",
    "    for category in cls_clusters:\n",
    "        if  i in cls_clusters[category]:\n",
    "            categories.append(category)\n",
    "            break\n",
    "            \n",
    "print(categories)\n",
    "# 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "data, target = ds.load_iris(return_X_y=True)\n",
    "data = data[:, [0, 2]] \n",
    "# 1.随机选择初始质心点\n",
    "tol = 0.0001   # 质心点稳定的误差\n",
    "cluster_num = 3  # 聚类的类别（经验 + 人的分析）、\n",
    "\n",
    "# 输出与中间数据缓冲\n",
    "# 质心点\n",
    "clusters = []   # 存放的是均值中心shape= (3, 4)\n",
    "\n",
    "#  聚类的样本集\n",
    "cls_clusters = {}   # 字典格式：{类别下标(0,1,2): [存放样本的下标] }     # 类别下标对应质心的下标\n",
    "\n",
    "# 质心初始化（在data中随机选择三个点）\n",
    "idx = np.random.choice( range(0, len(data)), cluster_num)\n",
    "for i in idx:\n",
    "    clusters.append(data[i])   # 取三个样本点作为随机质心点\n",
    "    # 聚类样本集的初始化\n",
    "\n",
    "for i in range(cluster_num): \n",
    "    cls_clusters[i] = []   # 初始化空的list\n",
    "\n",
    "is_cluster = True\n",
    "\n",
    "while is_cluster:\n",
    "    # 重新初始化聚类的样本集\n",
    "    cls_clusters = {}\n",
    "    for i in range(cluster_num): \n",
    "        cls_clusters[i] = []   # 初始化空的list\n",
    "        \n",
    "    # 2. 对样本点循环，计算到质心点的距离\n",
    "    for sample_idx in  range(len(data)):\n",
    "        # 计算到所有质心点的距离\n",
    "        # 保存到质心点的距离\n",
    "        distances = []\n",
    "        for cluster in clusters:\n",
    "            # 计算距离\n",
    "            # distance =  np.sqrt(np.dot(data[sample_idx] - cluster, data[sample_idx] - cluster))    # 计算两个样本的差\n",
    "            diff = (data[sample_idx] - cluster) **2\n",
    "            diff =diff.sum()\n",
    "            distance = np.sqrt(diff)\n",
    "            distances.append(distance)\n",
    "        # 3. 根据最小原则，对样本点进行聚类\n",
    "        # 找出最小值的下标(聚类的类别下标)\n",
    "        min_idx = np.argmin(distances)\n",
    "        cls_clusters[min_idx].append( sample_idx )\n",
    "    # print(cls_clusters)    \n",
    "    # 4. 重新计算质心点，从第2步开始重复（误差值，固定的循环步骤）\n",
    "    new_clusters = []     # 存放新的质心点\n",
    "\n",
    "    # 循环字典，计算新的聚类的质心点\n",
    "    for cls in cls_clusters:   # cls是字典的key，就是类别\n",
    "        # 取出对应类别的样本集的下标\n",
    "        data_cls_idx =  cls_clusters[cls]\n",
    "        # print(data_cls_idx)\n",
    "        # 根据聚类的下标计算均值\n",
    "        # 根据下标取样本\n",
    "        data_cls = data.take(data_cls_idx, axis=0)\n",
    "        cls_mean = data_cls.mean(axis=0)\n",
    "        # 产生新的质心点\n",
    "        new_clusters.append(cls_mean)\n",
    "\n",
    "    # 是否质心点稳定\n",
    "    # 计算新旧质心点的距离（误差）是否小于tol\n",
    "    is_cluster=False\n",
    "    for i in range(len(new_clusters)):\n",
    "        # 计算质心点的距离\n",
    "        delta = np.sqrt(((clusters[i] - new_clusters[i])**2).sum())\n",
    "        if delta > tol:\n",
    "            is_cluster = True\n",
    "            break\n",
    "    # 跟新新的质心点\n",
    "    clusters = new_clusters\n",
    "\n",
    "    \n",
    "# print(delta)\n",
    "# print('聚类结束')\n",
    "# print(cls_clusters[0])\n",
    "# print(cls_clusters[1])\n",
    "# print(cls_clusters[2])\n",
    "# 分类\n",
    "categories = []\n",
    "for i in range(len(data)):\n",
    "    # 判定样本点，在哪个类别\n",
    "    for category in cls_clusters:\n",
    "        if  i in cls_clusters[category]:\n",
    "            categories.append(category)\n",
    "            break\n",
    "            \n",
    "print(categories)\n",
    "\n",
    "# 可视化\n",
    "figure = plt.figure('K均值-2', figsize=[8, 6])\n",
    "ax =figure.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "# 样本点\n",
    "colors = mlp.colors.ListedColormap([(1,0,0),(0,1,0),(0,0,1)])\n",
    "\n",
    "ax.scatter(data[:50, 0], data[:50, 1], c=categories[0:50],   cmap=colors, marker='v')\n",
    "ax.scatter(data[50:100, 0], data[50:100, 1], c=categories[50:100],   cmap=colors, marker='>')\n",
    "ax.scatter(data[100:150, 0], data[100:150, 1], c=categories[100:150],   cmap=colors, marker='^')\n",
    "# 质心点\n",
    "clusters = np.array(clusters)\n",
    "\n",
    "ax.scatter(clusters[:,0], clusters[:,1], color=(0,1,1))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(((categories- target)==0).sum())   # \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用sklearn体验应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 1. 加载数据\n",
    "# data, target = ds.load_wine(return_X_y=True)\n",
    "data, target = ds.load_iris(return_X_y=True)\n",
    "\n",
    "# print((target==0).sum())\n",
    "# print((target==1).sum())\n",
    "# print((target==2).sum())\n",
    "# 2. 创建一个决策树分类器\n",
    "classifier = DecisionTreeClassifier()    # 采用默认参数\n",
    "# 3. 训练\n",
    "classifier.fit(data, target)\n",
    "# 4. 分类测试结果\n",
    "pre = classifier.predict(data)\n",
    "print(pre)\n",
    "(pre == target).sum()    # 过拟合现象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re = ds.load_iris()\n",
    "# for item in re:\n",
    "#     print(item, re[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归\n",
    "\n",
    "- 多元回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 3) (17, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([154.,  34.,  64.]), array([156.,  33.,  54.]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "from sklearn.tree import DecisionTreeRegressor    # 回归\n",
    "\n",
    "# 1. 加载数据\n",
    "data1, target1 = ds.load_linnerud(return_X_y=True)\n",
    "data = data1[0:17]\n",
    "target= target1[0:17]\n",
    "print(data.shape, target.shape)\n",
    "# 2. 创建一个决策树分类器\n",
    "regressor =  DecisionTreeRegressor()\n",
    "# 3. 训练\n",
    "regressor.fit(data, target)\n",
    "\n",
    "# 4. 预测测试结果\n",
    "pre = regressor.predict(data1)\n",
    "\n",
    "pre[18], target1[18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 决策树：\n",
    "    - 不管分类与预测，对训练样本都是100%正确。过拟合现象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# 引入模块（安装）\n",
    "# 决策树的过程可视化\n",
    "import numpy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import  tree\n",
    "from sklearn.externals.six import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot    # 单独安转\n",
    "import sklearn.datasets as ds\n",
    "\n",
    "# 训练决策树\n",
    "data, target = ds.load_iris(return_X_y=True)\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion='entropy')\n",
    "classifier.fit(data, target)    # 训练过程生成决策树\n",
    "\n",
    "# 根据决策树，绘制图形（模式）\n",
    "# 创建一个缓冲，存储输出\n",
    "buff = StringIO()    # 生成的图像数据\n",
    "\n",
    "# 把决策树导出为图像（IO缓冲）\n",
    "tree.export_graphviz(\n",
    "    classifier,  \n",
    "    out_file=buff,  \n",
    "    feature_names=['特征1', '特征2', '特征3', '特征4'], \n",
    "    class_names=['A类','B类','C类'],\n",
    "    filled=True,\n",
    "    rounded=True\n",
    ")\n",
    "\n",
    "# 保存为图像\n",
    "graphics = pydot.graph_from_dot_data(buff.getvalue())   # 把缓冲转换为图像对象\n",
    "print(len(graphics))\n",
    "graphics[0].write_svg('iris_tree.svg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树的数学基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思路\n",
    "- 任何的数据多个维度的特征。\n",
    "    - 根据特征的重要性，选择一个重要特征\n",
    "        - 特征重要性的选择标准（衡量标准）\n",
    "    - 根据重要特征的值，对样本进行决策\n",
    "        - 边界值的计算公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息论的基本概念\n",
    "- 信息论Shannon\n",
    "    - 根据样本计算的一个值：信息熵\n",
    "    \n",
    "- 信息论在决策树中提供两个核心值得计算理论依据：\n",
    "    - 特征选择\n",
    "    - 分类阈值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 不纯度（Impurity）\n",
    "    - 不纯的度量：\n",
    "        - 基尼指数  Gini\n",
    "        - 信息熵\n",
    "        - 分类误差\n",
    "\n",
    "- 疑问：\n",
    "    - 能度量不纯？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 信息熵（Entropy）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 假设样本$X$， 假设类别数是$m$, 每个类别的集合$[x_{i0}, x_{i1},\\dots,x_{in}]  , \\qquad  ,i \\in [0, 1,2,\\dots, m-1]$\n",
    "- $I _E = - \\sum \\limits _{i=1} ^ m p_i log(p_i) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $p_i = \\dfrac{N_i}{M} $, $N_i$标识i类的样本个数，$N$样本总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-22.95904245935251\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "E= [1500, 1, 1]\n",
    "\n",
    "I_E = 0\n",
    "\n",
    "for e in E:\n",
    "    I_E -= e/150.0 * math.log(e/150.0)\n",
    "\n",
    "print(I_E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 基尼指数（Gini Index）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $ I_G  = \\sum \\limits _{i=1}^m p_i (1- p_i) = \\sum \\limits _{i=1} ^m (p_i  - {p_i}^2) = 1- \\sum \\limits _{i=1} ^ m  {p_i}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分类误差(Classification Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $I _C = 1 - \\overset{m} { \\underset{i=1} {\\text{Max}}} \\  p_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息增益\n",
    "    - 用来分类阈值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树的数学模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 样本总体信息熵 - 分类信息熵\n",
    "    - 按照总体样本中每个类别的样本数来计算信息熵：样本总体信息熵\n",
    "    - $I_H = - p_A log(p_A) - p_B log(p_B) - p_C log(p_C)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.584962500721156"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "\n",
    "# 总体信息熵的计算函数封装\n",
    "def  calcute_total_entropy( train_labels):\n",
    "    \"\"\"\n",
    "    param: train_labels 训练样本的标签数据集\n",
    "    \n",
    "    return: 返回总体信息熵\n",
    "    \"\"\"\n",
    "    # 1. 统计每个类别的样本总数\n",
    "    label_num = {}   # key 种类的索引，value：类别总数\n",
    "    total_num = len(train_labels)   # 总得样本数\n",
    "    \n",
    "    # 统计每个标签值的总数量\n",
    "    for label in  train_labels:\n",
    "        if label not  in label_num:\n",
    "            label_num[label] = 0\n",
    "        label_num[label] += 1\n",
    "    \n",
    "    # print(label_num)    \n",
    "    #  根据统计结果，计算信息熵\n",
    "    entropy = 0.0\n",
    "    for  _, num in  label_num.items():\n",
    "        # 计算概率\n",
    "        p = num / total_num\n",
    "        entropy -= p * np.log2(p)       # 自然对数，采用的是2为底的对数\n",
    "    return entropy\n",
    "    # 2. 计算每个类别占比 = 类别的概率\n",
    "    \n",
    "    # 3. 根据信息熵公式，计算出总体样本信息熵。\n",
    "    \n",
    "data, target = ds.load_iris(return_X_y=True)\n",
    "\n",
    "t_entropy = calcute_total_entropy(target)\n",
    "t_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5849625 , 0.        , 1.        , 0.44506486, 0.14609425,\n",
       "       0.        , 0.        , 0.91829583, 0.        , 0.91829583,\n",
       "       0.        , 0.        , 0.15109697, 0.91829583, 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练决策树\n",
    "data, target = ds.load_iris(return_X_y=True)\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion='entropy')\n",
    "classifier.fit(data, target)    # 训练过程生成决策树\n",
    "classifier.tree_.impurity\n",
    "# help(classifier.tree_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666667"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "\n",
    "# 总体信息熵的计算函数封装\n",
    "def  calcute_total_gini( train_labels):\n",
    "    \"\"\"\n",
    "    param: train_labels 训练样本的标签数据集\n",
    "    \n",
    "    return: 返回总体信息熵\n",
    "    \"\"\"\n",
    "    # 1. 统计每个类别的样本总数\n",
    "    label_num = {}   # key 种类的索引，value：类别总数\n",
    "    total_num = len(train_labels)   # 总得样本数\n",
    "    \n",
    "    # 统计每个标签值的总数量\n",
    "    for label in  train_labels:\n",
    "        if label not  in label_num:\n",
    "            label_num[label] = 0\n",
    "        label_num[label] += 1\n",
    "    \n",
    "    # print(label_num)    \n",
    "    #  根据统计结果，计算信息熵\n",
    "    gini = 0.0\n",
    "    for  _, num in  label_num.items():\n",
    "        # 计算概率\n",
    "        p = num / total_num\n",
    "        gini += p * (1.0 - p)        # 基尼指数\n",
    "    return gini\n",
    "    # 2. 计算每个类别占比 = 类别的概率\n",
    "    \n",
    "    # 3. 根据信息熵公式，计算出总体样本信息熵。\n",
    "    \n",
    "data, target = ds.load_iris(return_X_y=True)\n",
    "\n",
    "t_entropy = calcute_total_gini(target)\n",
    "t_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 特征值信息熵\n",
    "    - 某个特征的信息不同\n",
    "    - 概率的计算的方式b\n",
    "    \n",
    "    - 计算某个特征的某个值的信息熵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5032583347756457"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "\n",
    "def calcute_value_entropy(train_data,  train_label, index,  value):\n",
    "    #  统计： 值出现的总频次，每个类别中出现的频次\n",
    "    total_num = 0  # 值value出现的总得频次\n",
    "    label_num = {}  # value出现在每个类别中的频次key：类别，value：频次\n",
    "    \n",
    "    # 开始循环统计(对index指定的特征值循环)\n",
    "    idx = 0  # 下标记录器\n",
    "    \n",
    "    for  v  in train_data[:, index]:\n",
    "        # 值出现才处理\n",
    "        if v == value:\n",
    "            total_num += 1\n",
    "            \n",
    "            # 下面分类计数\n",
    "            label = train_label[idx]   # 使用下标取出类别标签0，1，2\n",
    "            if label in  label_num:\n",
    "                label_num[label] += 1\n",
    "            else:\n",
    "                label_num[label] = 1  \n",
    "        idx += 1  # 随着循环，下标计数器需要递增 \n",
    "    \n",
    "    # print(label_num, total_num)\n",
    "    # 计算信息熵\n",
    "    entropy = 0.0\n",
    "    for _, num in label_num.items():\n",
    "        p = num / total_num\n",
    "        entropy -= p * np.log2(p)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "data,  target = ds.load_iris(return_X_y=True)\n",
    "v_entropy = calcute_value_entropy(data, target, 0,  5.1)  # 计算地哦一个特征中值为5.1的信息熵\n",
    "v_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 某个特征的所有特征值的信息熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4.3: 0.0,\n",
       " 4.4: 0.0,\n",
       " 4.5: 0.0,\n",
       " 4.6: 0.0,\n",
       " 4.7: 0.0,\n",
       " 4.8: 0.0,\n",
       " 4.9: 1.2516291673878228,\n",
       " 5.0: 0.7219280948873623,\n",
       " 5.1: 0.5032583347756457,\n",
       " 5.2: 0.8112781244591328,\n",
       " 5.3: 0.0,\n",
       " 5.4: 0.6500224216483541,\n",
       " 5.5: 0.863120568566631,\n",
       " 5.6: 0.6500224216483541,\n",
       " 5.7: 1.2987949406953985,\n",
       " 5.8: 1.4488156357251847,\n",
       " 5.9: 0.9182958340544896,\n",
       " 6.0: 0.9182958340544896,\n",
       " 6.1: 0.9182958340544896,\n",
       " 6.2: 1.0,\n",
       " 6.3: 0.9182958340544896,\n",
       " 6.4: 0.863120568566631,\n",
       " 6.5: 0.7219280948873623,\n",
       " 6.6: 0.0,\n",
       " 6.7: 0.954434002924965,\n",
       " 6.8: 0.9182958340544896,\n",
       " 6.9: 0.8112781244591328,\n",
       " 7.0: 0.0,\n",
       " 7.1: 0.0,\n",
       " 7.2: 0.0,\n",
       " 7.3: 0.0,\n",
       " 7.4: 0.0,\n",
       " 7.6: 0.0,\n",
       " 7.7: 0.0,\n",
       " 7.9: 0.0}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 某个特征的所有值信息熵\n",
    "def calcute_feature_values_entropy(train_data, train_label, index):\n",
    "    # 定义一个结构存储输出\n",
    "    fvs_entropy = {}  #  key:特征值，value：特征值信息熵\n",
    "    # 对指定特征的数据进行循环\n",
    "    for v in  train_data[:, index]:\n",
    "        # 如果已经计算，就直接下一条数据\n",
    "        if v not in fvs_entropy:   # 不出现，就计算信息熵， 出现则不计算。\n",
    "            entropy = calcute_value_entropy(train_data, train_label, index, v)\n",
    "            fvs_entropy[v] = entropy\n",
    "    return fvs_entropy\n",
    "            \n",
    "    \n",
    "    \n",
    "data,  target = ds.load_iris(return_X_y=True)\n",
    "f_vs_entropy= calcute_feature_values_entropy(data, target, 0)\n",
    "f_vs_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 条件熵\n",
    "    - 一个特征的所有值得信息熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 特征信息增益值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 计算分类的阈值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 选择特征\n",
    "    - 计算信息增益值\n",
    "        - 特征的信息熵计算\n",
    "            - 特征的某个值得信息熵\n",
    "        - 样本总体信息熵\n",
    "        \n",
    "- 不纯度\n",
    "    - 基尼计数\n",
    "    - 分类误差\n",
    "    - 熵            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总体的思路\n",
    "\n",
    "-  样本多个特征找到一个重要分类特征。\n",
    "    - 选择特征的标准值\n",
    "        - 特征值的信息熵    ：5.1在A类，B类，C类中的占比\n",
    "        - 特征的信息熵：5.1出现次数30， 150，占比：30/150=p_5.1  * 特征值的信息熵\n",
    "           - 信息增益比：   总体样本信息熵 - 特征信息熵：特征选择\n",
    "- 按照特征进行分类\n",
    "    - 分类阈值\n",
    "        - 按照信息增益比来分类：\n",
    "            - 多叉树\n",
    "                - 每个特征值分成类\n",
    "                    - 信息增益比非0，继续分类\n",
    "    \n",
    "    \n",
    "- 上面两个操作是相互关联\n",
    "\n",
    "- 信息熵\n",
    "    - 均衡度\n",
    "- 基尼指数\n",
    "\n",
    "- 分类误差（使用比较少）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets as ds\n",
    "\n",
    "data,target = ds.load_iris(return_X_y=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ID3算法\n",
    "    - 选择特征的算法：\n",
    "        - 特征信息熵：根据多个特征的信息熵，选择具有最大特征信息熵的特征作为分类特征。\n",
    "        - 计算公式：$I =  \\sum p_i  H_i$，其中的$i$是每一个特征值。$H_i$就是谬个特征值信息熵，$p_i$是特征值的占比（近似概率）\n",
    "    - 分类阈值\n",
    "        - 信息增益比\n",
    "        - 公式：$I =  I_T  - I_F$\n",
    "- C4.5算法\n",
    "- CART算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策的实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 理解纯度与信息熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5849625  0.         1.         0.44506486 0.14609425 0.\n",
      " 0.         0.91829583 0.         0.91829583 0.         0.\n",
      " 0.15109697 0.91829583 0.         0.         0.        ]\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "#  鸢尾花，观察sklearn决策树产生的树 \n",
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 创建决策树模型\n",
    "classifier  =  DecisionTreeClassifier(criterion='entropy')\n",
    "# 加载数据，训练\n",
    "data, target = ds.load_iris(return_X_y=True)\n",
    "classifier.fit(data, target)\n",
    "\n",
    "# 观察训练产生的二叉树\n",
    "tree = classifier.tree_\n",
    "print(tree.impurity)\n",
    "print(len(tree.impurity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.584962500721156"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "\n",
    "# 总体信息熵的计算函数封装\n",
    "def  calcute_total_entropy( train_labels):\n",
    "    \"\"\"\n",
    "    param: train_labels 训练样本的标签数据集\n",
    "    \n",
    "    return: 返回总体信息熵\n",
    "    \"\"\"\n",
    "    # 1. 统计每个类别的样本总数\n",
    "    label_num = {}   # key 种类的索引，value：类别总数\n",
    "    total_num = len(train_labels)   # 总得样本数\n",
    "    \n",
    "    # 统计每个标签值的总数量\n",
    "    for label in  train_labels:\n",
    "        if label not  in label_num:\n",
    "            label_num[label] = 0\n",
    "        label_num[label] += 1\n",
    "    \n",
    "    # print(label_num)    \n",
    "    #  根据统计结果，计算信息熵\n",
    "    entropy = 0.0\n",
    "    for  _, num in  label_num.items():\n",
    "        # 计算概率\n",
    "        p = num / total_num\n",
    "        entropy -= p * np.log2(p)       # 自然对数，采用的是2为底的对数\n",
    "    return entropy\n",
    "    # 2. 计算每个类别占比 = 类别的概率\n",
    "    \n",
    "    # 3. 根据信息熵公式，计算出总体样本信息熵。\n",
    "\n",
    "# 计算不纯度 = 信息熵\n",
    "data, target = ds.load_iris(return_X_y=True)\n",
    "\n",
    "t_entropy = calcute_total_entropy(target)\n",
    "t_entropy\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1626441180472606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 信息熵的公式\n",
    "nums = np.array([60, 60, 60, 20, 20])    # 不纯度，度量的是分类的均衡度\n",
    "t = nums.sum()\n",
    "e = 0\n",
    "for n in nums:\n",
    "    if  n != 0:\n",
    "        p = n / t\n",
    "        e -= p * np.log2(p)\n",
    "    \n",
    "print(e)\n",
    "\n",
    "1.0 * np.log2(1.0)\n",
    "\n",
    "# 分类来说：信息熵越大，越均衡，约不可分，这个特征不是我们的选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 样本总体信息熵\n",
    "    - 假设样本总数是$N$，类别有$m$个，每个类别的样本数$N_1, N_2, \\dots, N_m$，存在如下关系$N= \\sum \\limits _{i=1} ^ m N_i$\n",
    "    - $I_T = \\sum \\limits _{i=1} ^ m  \\dfrac{N_i}{N} \\  log (\\dfrac{N_i}{N})$\n",
    "    \n",
    "    - 如果使用概率的形式：$I_T = \\sum \\limits _{i=1} ^ m  p_i \\  log (p_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 能否计算每个特征的信息熵(所有特征值的信息熵的和【加权的（出现的频率）】)\n",
    "    - **特征值**信息熵\n",
    "    - **特征**信息熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 特征值信息熵\n",
    "    - 假设特征值$v$，特征值可能重复,总的数量是$N$，重复特征值也属于多个类别，类别数假设是$m$, 且假设每个类别数量$N_1,N_2,\\dots, N_m$\n",
    "    - 计算特征值的信息熵的公式：$I_V = \\sum \\limits _{i=1} ^ m  \\dfrac{N_i}{N} \\  log (\\dfrac{N_i}{N})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5032583347756457"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "\n",
    "def calcute_value_entropy(train_data,  train_label, index,  value):\n",
    "    #  统计： 值出现的总频次，每个类别中出现的频次\n",
    "    total_num = 0  # 值value出现的总得频次\n",
    "    label_num = {}  # value出现在每个类别中的频次key：类别，value：频次\n",
    "    \n",
    "    # 开始循环统计(对index指定的特征值循环)\n",
    "    idx = 0  # 下标记录器\n",
    "    \n",
    "    for  v  in train_data[:, index]:\n",
    "        # 值出现才处理\n",
    "        if v == value:\n",
    "            total_num += 1\n",
    "            \n",
    "            # 下面分类计数\n",
    "            label = train_label[idx]   # 使用下标取出类别标签0，1，2\n",
    "            if label in  label_num:\n",
    "                label_num[label] += 1\n",
    "            else:\n",
    "                label_num[label] = 1  \n",
    "        idx += 1  # 随着循环，下标计数器需要递增 \n",
    "    \n",
    "#     print(label_num, total_num)\n",
    "    # 计算信息熵\n",
    "    entropy = 0.0\n",
    "    for _, num in label_num.items():\n",
    "        p = num / total_num\n",
    "        entropy -= p * np.log2(p)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "data,  target = ds.load_iris(return_X_y=True)\n",
    "v_entropy = calcute_value_entropy(data, target, 0,  5.1)  # 计算地哦一个特征中值为5.1的信息熵\n",
    "v_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5032583347756457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 信息熵的公式\n",
    "nums = np.array([8, 1])    # 不纯度，度量的是分类的均衡度\n",
    "t = nums.sum()\n",
    "e = 0\n",
    "for n in nums:\n",
    "    if  n != 0:\n",
    "        p = n / t\n",
    "        e -= p * np.log2(p)\n",
    "    \n",
    "print(e)\n",
    "\n",
    "1.0 * np.log2(1.0)\n",
    "\n",
    "# 分类来说：信息熵越大，越均衡，约不可分，这个特征不是我们的选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 特征信息熵\n",
    "    - 假设某个特征，它的值有$[ v_1, v_2, \\dots, v_k ]$\n",
    "    - 假设每个值出现的次数$[N_1, N_2,\\dots, N_k]$, 总得次数$\\sum \\limits _{i=1} ^ k N_i = N$,$N$就是样本总数。\n",
    "    - 假设每个值得信息熵$[I_{v_1}, I_{v_2},\\dots, I_{v_k}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 特征的信息熵计算公式\n",
    "    - $I_F = \\dfrac{N_1}{N}  I_{v_1} + \\dfrac{N_2}{N} I_{v_2} + \\dots +  \\dfrac{N_k}{N} I_{v_k}$\n",
    "    - $I_F = \\sum \\limits _{i=1} ^k  \\dfrac{N_i}{N} I_{v_i}$\n",
    "    - $I_F = p_1  I_{v_1} + p_2 I_{v_2} + \\dots +  p_k I_{v_k}$\n",
    "    - $I_F = \\sum \\limits _{i=1} ^ k p_i  I_{v_i} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4.3: 0.0,\n",
       " 4.4: 0.0,\n",
       " 4.5: 0.0,\n",
       " 4.6: 0.0,\n",
       " 4.7: 0.0,\n",
       " 4.8: 0.0,\n",
       " 4.9: 1.2516291673878228,\n",
       " 5.0: 0.7219280948873623,\n",
       " 5.1: 0.5032583347756457,\n",
       " 5.2: 0.8112781244591328,\n",
       " 5.3: 0.0,\n",
       " 5.4: 0.6500224216483541,\n",
       " 5.5: 0.863120568566631,\n",
       " 5.6: 0.6500224216483541,\n",
       " 5.7: 1.2987949406953985,\n",
       " 5.8: 1.4488156357251847,\n",
       " 5.9: 0.9182958340544896,\n",
       " 6.0: 0.9182958340544896,\n",
       " 6.1: 0.9182958340544896,\n",
       " 6.2: 1.0,\n",
       " 6.3: 0.9182958340544896,\n",
       " 6.4: 0.863120568566631,\n",
       " 6.5: 0.7219280948873623,\n",
       " 6.6: 0.0,\n",
       " 6.7: 0.954434002924965,\n",
       " 6.8: 0.9182958340544896,\n",
       " 6.9: 0.8112781244591328,\n",
       " 7.0: 0.0,\n",
       " 7.1: 0.0,\n",
       " 7.2: 0.0,\n",
       " 7.3: 0.0,\n",
       " 7.4: 0.0,\n",
       " 7.6: 0.0,\n",
       " 7.7: 0.0,\n",
       " 7.9: 0.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算每个值得信息熵，就可以计算出特征的信息熵\n",
    "# 某个特征的所有值信息熵\n",
    "def calcute_feature_values_entropy(train_data, train_label, index):\n",
    "    # 定义一个结构存储输出\n",
    "    fvs_entropy = {}  #  key:特征值，value：特征值信息熵\n",
    "    # 对指定特征的数据进行循环\n",
    "    for v in  train_data[:, index]:\n",
    "        # 如果已经计算，就直接下一条数据\n",
    "        if v not in fvs_entropy:   # 不出现，就计算信息熵， 出现则不计算。\n",
    "            entropy = calcute_value_entropy(train_data, train_label, index, v)\n",
    "            fvs_entropy[v] = entropy\n",
    "    return fvs_entropy\n",
    "            \n",
    "    \n",
    "    \n",
    "data,  target = ds.load_iris(return_X_y=True)\n",
    "f_vs_entropy= calcute_feature_values_entropy(data, target, 0)\n",
    "f_vs_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 特征的信息熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8769376208910578, 0.5108699641236061, 1.4463165236458, 1.4358978386754417]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算特征信息熵\n",
    "\n",
    "def calculate_feature_entropy(data_, target_, index):\n",
    "    # 1. 计算出所有特征值的信息熵，只是利用上面的结果\n",
    "    f_vs_entropy= calcute_feature_values_entropy(data_, target_, index)\n",
    "    # 2. 根据每个值，统计出现的次数\n",
    "    total_num = len(target_)\n",
    "    entropy_ = 0.0\n",
    "    for  v_, e_ in f_vs_entropy.items():\n",
    "        # 统计v_出现的次数\n",
    "        v_num = (data[:, index] == v_).sum()\n",
    "        p = v_num / total_num\n",
    "        entropy_ +=  p * e_\n",
    "    return entropy_\n",
    "\n",
    "        \n",
    "def calcute_gain_entropy(data_, target_, index):\n",
    "    f_e = calculate_feature_entropy(data_, target_, index)\n",
    "    t_entropy = calcute_total_entropy(target)\n",
    "    return t_entropy - f_e   # 特征增益\n",
    "\n",
    "\n",
    "data,  target = ds.load_iris(return_X_y=True)\n",
    "all_gain = []\n",
    "for i in range(4):\n",
    "    all_gain.append(calcute_gain_entropy(data, target, i))\n",
    "all_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 特征的信息增益值\n",
    "    - $I_ R =  I_T - I _F$\n",
    "    - 选择最大增益值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ID3的算法：\n",
    "    1. 假设样本集$X$，类别数m类。\n",
    "    2. 计算所有特征的信息熵（信息增益值），\n",
    "    3. 根据信息熵（信息增益值）选择决策树的分类（分叉）特征，如果是特征信息熵，则选在最小信息熵的特征，如果是增益值，选择最大。\n",
    "    4. 对分类特征的所有特征值，按照特征值的个数（假设是k个）进行分叉，形成k个子节点数据集（k类数据集），每一个值有一个信息熵。\n",
    "    5. 开始对k个节点的数据集分别重复2的步骤，器重复条件，其对应值得信息熵不等于0。\n",
    "        - 当节点的样本集数量，小于某个数的时候，分叉就会失去意义，可以设置节点的分叉的最小数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ID3算法存在局限性\n",
    "    - 如果有一个待分类样本$(x_0, x_1,x_2,x_3)$，在已经训练出一个决策树的条件，进行分类判别：\n",
    "        - 已知决策树第一层，是特征3，使用待分类样本的特征的值$x_2$，匹配每个子节点。匹配成功，决策成功。如果匹配不成功，就无法分类。\n",
    "        - 问题的本质：\n",
    "            - 算法是连续（子节点分叉，理论上是无穷），实际上真实数据是离散的。\n",
    "        - 改进ID3，就必须离散化。\n",
    "            - 离散化：二分方式：形成二叉树。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分裂信息熵（特征）\n",
    "    - 特征分裂信息熵\n",
    "\n",
    "    - 注意：对应名词：特征信息熵\n",
    "        - 特征信息熵：$I _ F = \\sum p_i  I _{v_i} $\n",
    "        - 分裂信息熵：$I _ CF = \\sum  p_i log(p_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 信息增益比\n",
    "    - 信息增益比就是信息增益值与分裂信息熵的比值：    $IR_{X}=\\dfrac{I_G(X)} {I_S(X)} = \\dfrac{I_C - I_F(X) }{I_S(X)}$        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用增益比选择分类特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分类增益值\n",
    "    - 某个特征的值分成两个部分$A, B$， 计算出$A，B$样本集的特征信息熵,，并计算出增益值；\n",
    "    - 分类增益值$I _R = \\dfrac{N_A}{N} I_{G_A} +  \\dfrac{N_B}{N} I_{G_B}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 离散化\n",
    "    - 特征的特征值排序（升序），不同特征值的个数是N\n",
    "    - 特征值两两取均值，得到N-1平均值，\n",
    "    - 使用平均值作为阈值，把样本分成2类A，B\n",
    "    - 计算AB两类的分类增益值\n",
    "    - 选择最大的作为最终特征的分类阈值。\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 算法步骤\n",
    "    - 选择特征\n",
    "        - 特征的信息增益比\n",
    "            - 计算所以特征的信息增益值\n",
    "                - 计算某个特征的信息增益值\n",
    "                    1. 计算特征信息熵\n",
    "                        - 计算特征值的信息熵\n",
    "                    2. 计算样本的总体信息熵\n",
    "\n",
    "            - 计算所有特征的分裂信息熵\n",
    "                - 计算某个特征的分离信息熵\n",
    "                \n",
    "        - 结果：\n",
    "            - 使用最大的信息增益比作为特征选择的标准。\n",
    "        \n",
    "    - 计算阈值（争对某个特征）\n",
    "        - 离散化处理过程\n",
    "            - 特征的特征值排序（升序），不同特征值的个数是N\n",
    "            - 特征值两两取均值，得到N-1平均值，\n",
    "            - 使用平均值作为阈值，把样本分成2类A，B\n",
    "            - 计算AB两类的分类增益值\n",
    "            - 选择最大的作为最终特征的分类阈值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CART\n",
    "    - 在C4.5算法基础上，采用基尼指数代替信息熵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 作业：\n",
    "    - 阅读"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib Web可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 创建一个Django项目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 配置运行环境\n",
    "    - runserver   ip:port  \n",
    "    - 启动web服务\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 配置前端资源路径\n",
    "    - 创建目录\n",
    "    - 配置\n",
    "        - url\n",
    "        - 资源存放目录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 配置后端资源配置\n",
    "    - 代码代码开发\n",
    "    - urls配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在前端调用后端\n",
    "    - matplotlib产生图像。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
