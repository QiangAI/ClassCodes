{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 感知器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 感知器模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 感知器的提出，基本上提出了统一的模型\n",
    "    - 分类判定模型\n",
    "        - $y^{\\prime} = f(xW + b)$\n",
    "        \n",
    "    - 损失模型：\n",
    "        - $L(y, y^{\\prime}) = ？$非常多\n",
    "            - 均方损失函数：f(x)=x   ：线性回归\n",
    "            - 对数损失函数：\n",
    "                - sogmoid交叉熵 ： 逻辑回归\n",
    "                - softmax交叉熵\n",
    "            - hinge孙叔函数： linear SVM + kernel sVM\n",
    "            - huber损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 感知器的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.datasets  as ds\n",
    "\n",
    "# 1. 感知器的输出模型（预测模型）\n",
    "#    - 1.1. 输入数据（鸢尾花数据  100 * 4）\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 4))    # 也可以使用constan创建常张量，也可以使用Variable创建被管理张量（张量包装器）\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None))\n",
    "#    - 1.2. 训练的数据（权重矩阵 + 偏置项）：可训练的参数一定使用Variable包装器管理数据与生命周期\n",
    "w_v = tf.random.uniform(shape=(4, 1), minval=-0.1, maxval=0.1, dtype=np.float32)\n",
    "# w_v = np.random.uniform(low=-0.1, high=0.1, size=(4, 1))\n",
    "w = tf.Variable(w_v) \n",
    "# print(w)\n",
    "\n",
    "b_v = tf.random.uniform(shape=(), minval=-0.1, maxval=0.1, dtype=np.float32)\n",
    "# w_v = np.random.uniform(low=-0.1, high=0.1, size=(4, 1))\n",
    "b = tf.Variable(b_v) \n",
    "\n",
    "#    - 1.3. 激活函数\n",
    "# y_o = x @ w + b    # 内积 \n",
    "y_o = tf.add(tf.matmul(x, w) , b)\n",
    "\n",
    "# y_predict =  tf.sigmoid(y_o) # \n",
    "y_predict =  tf.sigmoid(y_o)\n",
    "\n",
    "# 2. 优化模型\n",
    "#    - 2.1. 损失函数（y , y'）\n",
    "# loss = tf.reduce_mean(tf.square( tf.subtract(y_o , y)))    #  1/n * (y-y)^2\n",
    "\n",
    "loss = tf.losses.sigmoid_cross_entropy(y, y_o)\n",
    "#    - 2.2. 损失函数最小的优化（梯度下降：封装独有的函数：学习率）\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "\n",
    "optimizer_op = optimizer.minimize(loss)\n",
    "\n",
    "# Graph的保存\n",
    "writer = tf.summary.FileWriter('./nn', tf.get_default_graph())\n",
    "\n",
    "writer.flush()\n",
    "writer.close()\n",
    "#3. 模型的执行(数据加载，格式化)\n",
    "data, target = ds.load_iris(return_X_y=True)\n",
    "data = data[50: 150]\n",
    "target =target[0 : 100]\n",
    "\n",
    "session =tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "#   - 3.1. 模型的训练 \n",
    "N = 10000\n",
    "batch = 10\n",
    "batch_size= len(data)//batch\n",
    "for n in range(N):\n",
    "    for i in range(batch_size):     # 随机梯度下降\n",
    "        session.run(\n",
    "            optimizer_op, \n",
    "            feed_dict={\n",
    "                x:data[i * batch: (i+1) * batch], \n",
    "                y:target[i * batch: (i+1) * batch]\n",
    "            }\n",
    "        )   # 保持维数相同\n",
    "    # 输出误差\n",
    "    if n % 100 == 0:\n",
    "        err = session.run(loss, feed_dict={x: data, y: target})\n",
    "        print(\"损失函数输出：\",  err)\n",
    "                                                                                        \n",
    "    \n",
    "#   - 3.2. 使用模型预测（图可视化）\n",
    "pre = session.run(y_predict, feed_dict={x: data})\n",
    "\n",
    "pre[pre>0.5] = 1\n",
    "pre[pre<=0.5] = 0\n",
    "print(pre.shape)\n",
    "\n",
    "(pre[:,0] == target).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前馈神经网络\n",
    "\n",
    "- 网络结构\n",
    "    1. 输入：4\n",
    "    2. 隐藏层：5    sigmoid    4 * 5\n",
    "    3. 隐藏层：3    sigmoid    5 * 3\n",
    "    4. 输出层:  3（3类样本：\\[1,0,0\\], \\[0,1,0\\],\\[0,0,1\\]）:    3 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeule 与package导入\n",
    "import tensorflow as tf\n",
    "import sklearn.datasets as ds\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型\n",
    "#  ------------------\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 4))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 3))  # 0 = [1,0,0]  1 =[0,1,0]  2= [0,0,1]\n",
    "\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练的变量\n",
    "# 第一层的权重\n",
    "w_1 = tf.Variable(tf.random.uniform(shape=(4, 5), minval=-0.01, maxval=0.01, dtype=np.float32))\n",
    "b_1 = tf.Variable(tf.random.uniform(shape=(1, 5), minval=-0.01, maxval=0.01, dtype=np.float32))\n",
    "# 第二层\n",
    "\n",
    "w_2 = tf.Variable(tf.random.uniform(shape=(5, 3), minval=-0.01, maxval=0.01, dtype=np.float32))\n",
    "b_2 = tf.Variable(tf.random.uniform(shape=(1, 3), minval=-0.01, maxval=0.01, dtype=np.float32))\n",
    "\n",
    "# 第三层\n",
    "w_3 = tf.Variable(tf.random.uniform(shape=(3, 3), minval=-0.01, maxval=0.01, dtype=np.float32))\n",
    "b_3 = tf.Variable(tf.random.uniform(shape=(1, 3), minval=-0.01, maxval=0.01, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向后的输出计算\n",
    "# 第一层输出\n",
    "yo_1 = tf.add(tf.matmul(x, w_1), b_1)\n",
    "yp_1 = tf.sigmoid(yo_1)\n",
    "# 第二层输出\n",
    "yo_2 = tf.add(tf.matmul(yp_1, w_2), b_2)\n",
    "yp_2 = tf.sigmoid(yo_2)   #tf.nn.relu(yo_12)\n",
    "# 第三层输出\n",
    "yo_3 = tf.add(tf.matmul(yp_2,  w_3), b_3)\n",
    "\n",
    "\n",
    "yo = tf.sigmoid(yo_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  前馈模型（损失模型，优化模型）\n",
    "loss = tf.losses.sigmoid_cross_entropy(y, yo_3)    # 可以自己定义\n",
    "# loss = 1.0/2 * (y- yo_3) * (y-yo_3)   均方差\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "\n",
    "# 优化操作\n",
    "train_op = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "data,  target = ds.load_iris(return_X_y=True)\n",
    "# 数据格式化\n",
    "X = data\n",
    "Y = np.zeros(shape=(len(target), 3), dtype=np.float32)\n",
    "for i in range(len(target)):\n",
    "    l_pos= target[i]\n",
    "    Y[i][l_pos] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "损失函数输出： 0.63651544\n",
      "损失函数输出： 0.6366941\n",
      "损失函数输出： 0.63668823\n",
      "损失函数输出： 0.6366828\n",
      "损失函数输出： 0.6366777\n",
      "损失函数输出： 0.6366728\n",
      "损失函数输出： 0.6366679\n",
      "损失函数输出： 0.63666296\n",
      "损失函数输出： 0.6366573\n",
      "损失函数输出： 0.63665\n",
      "损失函数输出： 0.6366375\n",
      "损失函数输出： 0.63661003\n",
      "损失函数输出： 0.6365384\n",
      "损失函数输出： 0.6363268\n",
      "损失函数输出： 0.63562113\n",
      "损失函数输出： 0.63249594\n",
      "损失函数输出： 0.602258\n",
      "损失函数输出： 0.43252695\n",
      "损失函数输出： 0.3506258\n",
      "损失函数输出： 0.3299855\n",
      "损失函数输出： 0.32156396\n",
      "损失函数输出： 0.3165646\n",
      "损失函数输出： 0.31235504\n",
      "损失函数输出： 0.30702332\n",
      "损失函数输出： 0.30002865\n",
      "损失函数输出： 0.292916\n",
      "损失函数输出： 0.28482714\n",
      "损失函数输出： 0.26967207\n",
      "损失函数输出： 0.2344959\n",
      "损失函数输出： 0.18500867\n",
      "损失函数输出： 0.14299764\n",
      "损失函数输出： 0.11581217\n",
      "损失函数输出： 0.099096775\n",
      "损失函数输出： 0.08845298\n",
      "损失函数输出： 0.081269406\n",
      "损失函数输出： 0.076098576\n",
      "损失函数输出： 0.07215108\n",
      "损失函数输出： 0.068998866\n",
      "损失函数输出： 0.066396\n",
      "损失函数输出： 0.06418565\n",
      "损失函数输出： 0.062261164\n",
      "损失函数输出： 0.0605515\n",
      "损失函数输出： 0.05901106\n",
      "损失函数输出： 0.057611562\n",
      "损失函数输出： 0.0563342\n",
      "损失函数输出： 0.055165008\n",
      "损失函数输出： 0.05409305\n",
      "损失函数输出： 0.05310882\n",
      "损失函数输出： 0.052204467\n",
      "损失函数输出： 0.051372837\n",
      "损失函数输出： 0.050607167\n",
      "损失函数输出： 0.04990149\n",
      "损失函数输出： 0.049250454\n",
      "损失函数输出： 0.048649196\n",
      "损失函数输出： 0.04809262\n",
      "损失函数输出： 0.047577035\n",
      "损失函数输出： 0.047098324\n",
      "损失函数输出： 0.04665329\n",
      "损失函数输出： 0.046238925\n",
      "损失函数输出： 0.045852475\n",
      "损失函数输出： 0.045491014\n",
      "损失函数输出： 0.04515286\n",
      "损失函数输出： 0.04483598\n",
      "损失函数输出： 0.0445384\n",
      "损失函数输出： 0.04425852\n",
      "损失函数输出： 0.04399466\n",
      "损失函数输出： 0.04374603\n",
      "损失函数输出： 0.04351122\n",
      "损失函数输出： 0.043289095\n",
      "损失函数输出： 0.043078706\n",
      "损失函数输出： 0.042879406\n",
      "损失函数输出： 0.04268999\n",
      "损失函数输出： 0.042509668\n",
      "损失函数输出： 0.04233821\n",
      "损失函数输出： 0.042174913\n",
      "损失函数输出： 0.04201911\n",
      "损失函数输出： 0.041870203\n",
      "损失函数输出： 0.04172783\n",
      "损失函数输出： 0.041591547\n",
      "损失函数输出： 0.041460786\n",
      "损失函数输出： 0.041335296\n",
      "损失函数输出： 0.041214686\n",
      "损失函数输出： 0.04109876\n",
      "损失函数输出： 0.04098688\n",
      "损失函数输出： 0.04087893\n",
      "损失函数输出： 0.04077483\n",
      "损失函数输出： 0.040674176\n",
      "损失函数输出： 0.040576648\n",
      "损失函数输出： 0.040482022\n",
      "损失函数输出： 0.040390193\n",
      "损失函数输出： 0.040300965\n",
      "损失函数输出： 0.040214006\n",
      "损失函数输出： 0.040129133\n",
      "损失函数输出： 0.04004626\n",
      "损失函数输出： 0.039965067\n",
      "损失函数输出： 0.039885297\n",
      "损失函数输出： 0.03980693\n",
      "损失函数输出： 0.039729528\n",
      "损失函数输出： 0.039653156\n",
      "损失函数输出： 0.039577197\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "N = 10000\n",
    "batch = 10\n",
    "batch_size= len(X)//batch\n",
    "for n in range(N):\n",
    "    for i in range(batch_size):     # 随机梯度下降\n",
    "        session.run(\n",
    "            train_op, \n",
    "            feed_dict={\n",
    "                x:X[i * batch: (i+1) * batch], \n",
    "                y:Y[i * batch: (i+1) * batch]\n",
    "            }\n",
    "        )   # 保持维数相同\n",
    "    # 输出误差\n",
    "    if n % 100 == 0:\n",
    "        err = session.run(loss, feed_dict={x: X, y: Y})\n",
    "        print(\"损失函数输出：\",  err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9838090e-01, 1.7188787e-03, 1.1026859e-06],\n",
       "       [9.9826348e-01, 1.8410683e-03, 1.1026859e-06],\n",
       "       [9.9834311e-01, 1.7583072e-03, 1.1026859e-06],\n",
       "       [9.9821031e-01, 1.8960238e-03, 1.1622906e-06],\n",
       "       [9.9838936e-01, 1.7099380e-03, 1.0430813e-06],\n",
       "       [9.9835932e-01, 1.7413199e-03, 1.1026859e-06],\n",
       "       [9.9833035e-01, 1.7715991e-03, 1.1026859e-06],\n",
       "       [9.9833614e-01, 1.7655790e-03, 1.1026859e-06],\n",
       "       [9.9816155e-01, 1.9463599e-03, 1.1920929e-06],\n",
       "       [9.9827218e-01, 1.8320680e-03, 1.1622906e-06],\n",
       "       [9.9839401e-01, 1.7051101e-03, 1.0430813e-06],\n",
       "       [9.9828398e-01, 1.8197298e-03, 1.1622906e-06],\n",
       "       [9.9828190e-01, 1.8220246e-03, 1.1622906e-06],\n",
       "       [9.9835908e-01, 1.7416179e-03, 1.1026859e-06],\n",
       "       [9.9843782e-01, 1.6591549e-03, 1.0728836e-06],\n",
       "       [9.9843085e-01, 1.6664565e-03, 1.1324883e-06],\n",
       "       [9.9841952e-01, 1.6784370e-03, 1.0430813e-06],\n",
       "       [9.9837023e-01, 1.7299950e-03, 1.1026859e-06],\n",
       "       [9.9836814e-01, 1.7321408e-03, 1.1026859e-06],\n",
       "       [9.9838817e-01, 1.7112792e-03, 1.0430813e-06],\n",
       "       [9.9828327e-01, 1.8205941e-03, 1.1622906e-06],\n",
       "       [9.9836481e-01, 1.7356277e-03, 1.1622906e-06],\n",
       "       [9.9842548e-01, 1.6721189e-03, 1.0430813e-06],\n",
       "       [9.9807340e-01, 2.0370185e-03, 1.1622906e-06],\n",
       "       [9.9803746e-01, 2.0738840e-03, 1.1324883e-06],\n",
       "       [9.9812591e-01, 1.9830167e-03, 1.1920929e-06],\n",
       "       [9.9824560e-01, 1.8595755e-03, 1.1622906e-06],\n",
       "       [9.9836302e-01, 1.7374754e-03, 1.1026859e-06],\n",
       "       [9.9837112e-01, 1.7290115e-03, 1.1026859e-06],\n",
       "       [9.9819589e-01, 1.9109249e-03, 1.1324883e-06],\n",
       "       [9.9815607e-01, 1.9519627e-03, 1.1324883e-06],\n",
       "       [9.9832302e-01, 1.7792881e-03, 1.1026859e-06],\n",
       "       [9.9842358e-01, 1.6741753e-03, 1.1026859e-06],\n",
       "       [9.9843299e-01, 1.6642809e-03, 1.0430813e-06],\n",
       "       [9.9824286e-01, 1.8624067e-03, 1.1026859e-06],\n",
       "       [9.9837923e-01, 1.7206371e-03, 1.1026859e-06],\n",
       "       [9.9840593e-01, 1.6927123e-03, 1.0430813e-06],\n",
       "       [9.9839509e-01, 1.7040670e-03, 1.1622906e-06],\n",
       "       [9.9827313e-01, 1.8311441e-03, 1.1026859e-06],\n",
       "       [9.9834126e-01, 1.7601848e-03, 1.1026859e-06],\n",
       "       [9.9838662e-01, 1.7129481e-03, 1.0430813e-06],\n",
       "       [9.9759936e-01, 2.5191009e-03, 1.4305115e-06],\n",
       "       [9.9832737e-01, 1.7747283e-03, 1.1026859e-06],\n",
       "       [9.9821973e-01, 1.8861890e-03, 1.1026859e-06],\n",
       "       [9.9822873e-01, 1.8769205e-03, 1.1026859e-06],\n",
       "       [9.9822164e-01, 1.8842220e-03, 1.1622906e-06],\n",
       "       [9.9837953e-01, 1.7203391e-03, 1.0430813e-06],\n",
       "       [9.9830151e-01, 1.8014610e-03, 1.1622906e-06],\n",
       "       [9.9839151e-01, 1.7077923e-03, 1.1026859e-06],\n",
       "       [9.9834698e-01, 1.7542243e-03, 1.0430813e-06],\n",
       "       [2.6223361e-03, 9.9541825e-01, 2.6348531e-03],\n",
       "       [2.3699403e-03, 9.9579215e-01, 2.8308332e-03],\n",
       "       [2.2132993e-03, 9.9589622e-01, 3.0473173e-03],\n",
       "       [2.1549463e-03, 9.9577773e-01, 3.2306015e-03],\n",
       "       [2.1413863e-03, 9.9573618e-01, 3.2833219e-03],\n",
       "       [2.0492971e-03, 9.9511939e-01, 3.8709641e-03],\n",
       "       [2.0914376e-03, 9.9545634e-01, 3.5618842e-03],\n",
       "       [3.0087233e-03, 9.9479854e-01, 2.4110079e-03],\n",
       "       [2.4562478e-03, 9.9567342e-01, 2.7550459e-03],\n",
       "       [2.1845698e-03, 9.9583912e-01, 3.1351447e-03],\n",
       "       [2.5590360e-03, 9.9551487e-01, 2.6793182e-03],\n",
       "       [2.2908747e-03, 9.9587393e-01, 2.9197931e-03],\n",
       "       [2.7025938e-03, 9.9529105e-01, 2.5832057e-03],\n",
       "       [1.9802749e-03, 9.9436510e-01, 4.5341253e-03],\n",
       "       [2.9925704e-03, 9.9482453e-01, 2.4192929e-03],\n",
       "       [2.7049780e-03, 9.9528682e-01, 2.5818050e-03],\n",
       "       [1.5938282e-03, 9.8327708e-01, 1.4153421e-02],\n",
       "       [2.7827322e-03, 9.9516290e-01, 2.5346875e-03],\n",
       "       [1.1285841e-03, 9.0310770e-01, 8.7464452e-02],\n",
       "       [2.6468337e-03, 9.9537838e-01, 2.6192963e-03],\n",
       "       [5.1611662e-04, 1.2037143e-01, 8.8010329e-01],\n",
       "       [2.7434230e-03, 9.9522501e-01, 2.5584698e-03],\n",
       "       [6.4218044e-04, 3.0823499e-01, 6.8579960e-01],\n",
       "       [2.1863282e-03, 9.9586320e-01, 3.1177700e-03],\n",
       "       [2.6539862e-03, 9.9536753e-01, 2.6142299e-03],\n",
       "       [2.5940835e-03, 9.9546200e-01, 2.6541948e-03],\n",
       "       [2.2135079e-03, 9.9589741e-01, 3.0460954e-03],\n",
       "       [1.0392964e-03, 8.5678148e-01, 1.3136935e-01],\n",
       "       [2.0095706e-03, 9.9471343e-01, 4.2294860e-03],\n",
       "       [3.2218099e-03, 9.9445778e-01, 2.3072958e-03],\n",
       "       [2.6367605e-03, 9.9539399e-01, 2.6259422e-03],\n",
       "       [2.8572977e-03, 9.9504304e-01, 2.4918318e-03],\n",
       "       [2.7517378e-03, 9.9521160e-01, 2.5534630e-03],\n",
       "       [3.9887428e-04, 3.2884598e-02, 9.6845186e-01],\n",
       "       [1.1593401e-03, 9.1495317e-01, 7.6363772e-02],\n",
       "       [2.1723211e-03, 9.9581957e-01, 3.1710565e-03],\n",
       "       [2.2858381e-03, 9.9588382e-01, 2.9231012e-03],\n",
       "       [2.1873713e-03, 9.9586660e-01, 3.1137168e-03],\n",
       "       [2.4746358e-03, 9.9564272e-01, 2.7422309e-03],\n",
       "       [2.2459328e-03, 9.9589658e-01, 2.9869974e-03],\n",
       "       [2.0519197e-03, 9.9514395e-01, 3.8491786e-03],\n",
       "       [2.1561682e-03, 9.9578500e-01, 3.2239556e-03],\n",
       "       [2.5840402e-03, 9.9547708e-01, 2.6614666e-03],\n",
       "       [2.9844940e-03, 9.9483764e-01, 2.4234354e-03],\n",
       "       [2.2199750e-03, 9.9589223e-01, 3.0369163e-03],\n",
       "       [2.5566518e-03, 9.9551898e-01, 2.6807785e-03],\n",
       "       [2.3674369e-03, 9.9579376e-01, 2.8340220e-03],\n",
       "       [2.5432408e-03, 9.9554074e-01, 2.6899278e-03],\n",
       "       [3.5772026e-03, 9.9388599e-01, 2.1589100e-03],\n",
       "       [2.4110377e-03, 9.9573559e-01, 2.7941167e-03],\n",
       "       [3.5747886e-04, 1.8505991e-02, 9.8254228e-01],\n",
       "       [3.6364794e-04, 2.0258635e-02, 9.8083794e-01],\n",
       "       [3.6099553e-04, 1.9460380e-02, 9.8161483e-01],\n",
       "       [3.6409497e-04, 2.0372957e-02, 9.8072666e-01],\n",
       "       [3.5828352e-04, 1.8745393e-02, 9.8230970e-01],\n",
       "       [3.5819411e-04, 1.8688440e-02, 9.8236513e-01],\n",
       "       [3.7261844e-04, 2.3031265e-02, 9.7813308e-01],\n",
       "       [3.6138296e-04, 1.9584388e-02, 9.8149419e-01],\n",
       "       [3.6057830e-04, 1.9372612e-02, 9.8170012e-01],\n",
       "       [3.5864115e-04, 1.8801153e-02, 9.8225546e-01],\n",
       "       [4.1055679e-04, 3.8250715e-02, 9.6314144e-01],\n",
       "       [3.6764145e-04, 2.1427393e-02, 9.7969913e-01],\n",
       "       [3.6558509e-04, 2.0812929e-02, 9.8029816e-01],\n",
       "       [3.6054850e-04, 1.9347250e-02, 9.8172468e-01],\n",
       "       [3.5825372e-04, 1.8694699e-02, 9.8235893e-01],\n",
       "       [3.6191940e-04, 1.9766122e-02, 9.8131722e-01],\n",
       "       [3.7544966e-04, 2.3944348e-02, 9.7724062e-01],\n",
       "       [3.5953522e-04, 1.9073665e-02, 9.8199069e-01],\n",
       "       [3.5744905e-04, 1.8476605e-02, 9.8257089e-01],\n",
       "       [3.9008260e-04, 2.9294908e-02, 9.7199035e-01],\n",
       "       [3.6036968e-04, 1.9299656e-02, 9.8177111e-01],\n",
       "       [3.6418438e-04, 2.0398557e-02, 9.8070157e-01],\n",
       "       [3.5804510e-04, 1.8665403e-02, 9.8238748e-01],\n",
       "       [4.2670965e-04, 4.6703368e-02, 9.5473409e-01],\n",
       "       [3.6343932e-04, 2.0178646e-02, 9.8091590e-01],\n",
       "       [3.7547946e-04, 2.3964554e-02, 9.7722101e-01],\n",
       "       [4.7168136e-04, 7.7604949e-02, 9.2366499e-01],\n",
       "       [4.4989586e-04, 6.1152935e-02, 9.4026154e-01],\n",
       "       [3.5914779e-04, 1.8952370e-02, 9.8210871e-01],\n",
       "       [4.3392181e-04, 5.0897866e-02, 9.5054573e-01],\n",
       "       [3.6257505e-04, 1.9926101e-02, 9.8116171e-01],\n",
       "       [3.8182735e-04, 2.6152819e-02, 9.7507739e-01],\n",
       "       [3.5855174e-04, 1.8777311e-02, 9.8227870e-01],\n",
       "       [5.9524179e-04, 2.2815192e-01, 7.6891685e-01],\n",
       "       [3.7261844e-04, 2.3016900e-02, 9.7814751e-01],\n",
       "       [3.5965443e-04, 1.9116789e-02, 9.8194891e-01],\n",
       "       [3.5867095e-04, 1.8819094e-02, 9.8223805e-01],\n",
       "       [3.7553906e-04, 2.3984581e-02, 9.7720128e-01],\n",
       "       [4.7346950e-04, 7.9031348e-02, 9.2222005e-01],\n",
       "       [3.7539005e-04, 2.3944646e-02, 9.7724032e-01],\n",
       "       [3.5893917e-04, 1.8885404e-02, 9.8217362e-01],\n",
       "       [3.7908554e-04, 2.5210887e-02, 9.7600049e-01],\n",
       "       [3.6364794e-04, 2.0258635e-02, 9.8083794e-01],\n",
       "       [3.5858154e-04, 1.8804014e-02, 9.8225284e-01],\n",
       "       [3.5846233e-04, 1.8748373e-02, 9.8230684e-01],\n",
       "       [3.6537647e-04, 2.0745486e-02, 9.8036379e-01],\n",
       "       [3.7404895e-04, 2.3502439e-02, 9.7767282e-01],\n",
       "       [3.7908554e-04, 2.5211722e-02, 9.7599971e-01],\n",
       "       [3.6072731e-04, 1.9388884e-02, 9.8168421e-01],\n",
       "       [3.8099289e-04, 2.5866332e-02, 9.7535807e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "pre = session.run(\n",
    "    yo, \n",
    "    feed_dict={\n",
    "        x:X\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_pre = pre.argmax(axis=1)\n",
    "(o_pre == target).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.7447284 , -0.4268512 , -2.064081  , -0.41228718, -1.7928782 ],\n",
       "       [-2.0035727 , -1.6513062 , -1.6261929 , -1.6401    , -2.0889754 ],\n",
       "       [ 3.282474  ,  2.5860765 ,  3.4433851 ,  2.5407963 ,  3.3863845 ],\n",
       "       [ 4.152177  ,  1.338027  ,  4.3500047 ,  1.337834  ,  4.2308455 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(w_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.719931  , -0.27585724, -4.842547  , -0.25763616, -4.804512  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.6204336, -1.6428704, -3.9158003],\n",
       "       [-3.263194 , -3.5470624,  1.9251413],\n",
       "       [-1.6815736, -1.7028964, -4.097348 ],\n",
       "       [-3.2157123, -3.4939075,  1.8701997],\n",
       "       [-1.7003876, -1.7293723, -4.022923 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(w_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 可视化（2维，网格可视化）： 分类曲线是线性还是非线性。\n",
    "\n",
    "# 2. 把上面的数据集使用图像测试效果。\n",
    "\n",
    "# 3. 交叉验证训练\n",
    "\n",
    "# 4. 综合项目的数据集使用神经网络做分类\n",
    "\n",
    "# 5. 利用sklearn的classification-report, \n",
    "\n",
    "# 6. AUC曲线绘制出来 ROC\n",
    "147/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
